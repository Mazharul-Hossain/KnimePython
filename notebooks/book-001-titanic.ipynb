{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster\n",
    "\n",
    "It is the [Titanic](https://www.kaggle.com/c/titanic/) competition from Kaggle. Download all the data from kaggle and put it in <i>titanic</i> folder.\n",
    "\n",
    "This notebook uses [hsi_env](../environments/hsi_env.yml) for running. Take a look in [README](../environments/README.md) for details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure and download the dataset from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look into [kaggle-api](https://github.com/Kaggle/kaggle-api) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! E:/ProgramData/Anaconda3/envs/hsi_env/Scripts/pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! kaggle competitions download -c titanic\n",
    "# ! unzip titanic.zip -d titanic\n",
    "# ! del titanic.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"titanic/train.csv\")\n",
    "# Survived column is not at the end\n",
    "training['Survived'] = training.pop('Survived')\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Remove NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mean = 0\n",
    "fare_mean = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(X, train=True):\n",
    "    global age_mean, fare_mean\n",
    "    \n",
    "    if train:\n",
    "        age_mean = X[\"Age\"].mean()\n",
    "        fare_mean = X[\"Fare\"].mean()\n",
    "\n",
    "    X[\"Age\"] = X[\"Age\"].fillna(age_mean)\n",
    "    X[\"Fare\"] = X[\"Fare\"].fillna(fare_mean)\n",
    "    \n",
    "    X[\"Cabin\"] = X[\"Cabin\"].fillna(\"NaN\")\n",
    "    X[\"Embarked\"] = X[\"Embarked\"].fillna(\"NaN\")\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = remove_nan(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[training.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = training.iloc[:, :-1],training.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Encoding data\n",
    "\n",
    "[How to handle categorical data in scikit with pandas](https://www.kaggle.com/getting-started/27270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titan_oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "norm_sc = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(X, train=True):\n",
    "    global titan_oe, norm_sc\n",
    "\n",
    "    X['Male'] = X['Sex'].map( {'male':0, 'female':1} )\n",
    "\n",
    "    if train:\n",
    "        titan_oe.fit( X[ [\"Cabin\",\"Embarked\"] ] )\n",
    "        norm_sc.fit( X[ [\"Age\", \"Fare\"] ] )\n",
    "\n",
    "    X[ [\"Cabin\", \"Embarked\"] ] = titan_oe.transform( X[ [\"Cabin\",\"Embarked\"] ] )\n",
    "    X[ [\"Age\", \"Fare\"] ] = norm_sc.transform( X[ [\"Age\", \"Fare\"] ] )\n",
    "\n",
    "    X = X.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Sex\"])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encode_data(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Principal Component Analysis(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components = 8) \n",
    "\n",
    "# principalComponents = pca.fit_transform(X.values)\n",
    "# ev=pca.explained_variance_ratio_\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(np.cumsum(ev))\n",
    "# plt.xlabel('Number of components')\n",
    "# plt.ylabel('Cumulative explained variance')\n",
    "# plt.grid(True, alpha=0.5)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_com = 8  # CEV is saturated\n",
    "pca = PCA(n_components=n_com)\n",
    "\n",
    "X_pca = pca.fit_transform(X.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Check all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbf_svc = SVC(kernel='rbf', cache_size=1024, verbose=True, max_iter=10000)\n",
    "# rbf_svc.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = rbf_svc.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred, target_names = [\"Dead\", \"Alive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(n_jobs=-1, max_iter=10000)\n",
    "# lr.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = lr.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred, target_names = [\"Dead\", \"Alive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier() )\n",
    "\n",
    "# params = {\n",
    "#     'n_estimators': [int(x) for x in np.linspace(start = 80, stop = 200, num = 10)],\n",
    "#     'learning_rate': [0.01, 0.1, 0.5, 1],\n",
    "#     'base_estimator__criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [5, 9, 14, 19],\n",
    "#     'min_samples_split': [3, 5, 7],\n",
    "#     'base_estimator__min_samples_leaf': [1, 3, 5],\n",
    "#     'base_estimator__splitter': ['best', 'random'],\n",
    "#     'base_estimator__max_features': [None, 'auto', 'log2'],\n",
    "#     'base_estimator__max_leaf_nodes': [None, 5, 9],\n",
    "#     'base_estimator__class_weight': [None, 'balanced']\n",
    "# }\n",
    "\n",
    "# gs = HalvingRandomSearchCV(\n",
    "#     ada, param_distributions=params, scoring='accuracy', verbose=1\n",
    "# )\n",
    "\n",
    "# gs.fit(X_pca, y)\n",
    "# gs.best_estimator_, gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 Calibrated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrated_forest = CalibratedClassifierCV(\n",
    "#     base_estimator=RandomForestClassifier(n_jobs=-1), \n",
    "#     cv=5, n_jobs=-1)\n",
    "\n",
    "# # RandomForestClassifier().get_params().keys()\n",
    "# params = {\n",
    "#     'method': ['sigmoid', 'isotonic'],\n",
    "#     'ensemble': [True, False],\n",
    "#     'base_estimator__n_estimators': [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)],\n",
    "#     'base_estimator__criterion': ['gini', 'entropy'],\n",
    "#     'base_estimator__max_depth': [None, 5, 10, 15, 20],\n",
    "#     'base_estimator__min_samples_split': [0.1, 0.3, 0.5, 3, 5, 7],\n",
    "#     'base_estimator__min_samples_leaf': [0.1, 0.3, 0.5, 1, 3, 5],\n",
    "#     'base_estimator__max_features': ['sqrt', 'auto', 'log2'],\n",
    "#     'base_estimator__max_leaf_nodes': [None, 5, 9],\n",
    "#     'base_estimator__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "# }\n",
    "\n",
    "# gs = HalvingRandomSearchCV(\n",
    "#     calibrated_forest, param_distributions=params, scoring='accuracy', verbose=1\n",
    "# )\n",
    "\n",
    "# gs.fit(X, y)\n",
    "# gs.best_estimator_, gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.5 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf =RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# # RandomForestClassifier().get_params().keys()\n",
    "# params = {\n",
    "#     'n_estimators': [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)],\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [None, 5, 10, 15, 20],\n",
    "#     'min_samples_split': [0.1, 0.3, 0.5, 3, 5, 7],\n",
    "#     'min_samples_leaf': [0.1, 0.3, 0.5, 1, 3, 5],\n",
    "#     'max_features': ['sqrt', 'auto', 'log2'],\n",
    "#     'max_leaf_nodes': [None, 5, 9],\n",
    "#     'class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "# }\n",
    "\n",
    "# gs = HalvingRandomSearchCV(\n",
    "#     rf, param_distributions=params, scoring='accuracy', verbose=1\n",
    "# )\n",
    "\n",
    "# gs.fit(X, y)\n",
    "# gs.best_estimator_, gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_models(models, X, y):\n",
    "\t# evaluate each model in turn\n",
    "\tseed = 42\n",
    "\tresults = []\n",
    "\tnames = []\n",
    "\n",
    "\tscoring = 'accuracy'\n",
    "\tk_fold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "\tfor name, model in models:\n",
    "\t\tcv_results = model_selection.cross_val_score(model, X, y, cv=k_fold, scoring=scoring)\n",
    "\t\tresults.append(cv_results)\n",
    "\t\tnames.append(name)\n",
    "\t\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\t\tprint(msg)\n",
    "\treturn names, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(names, results):\n",
    "    # boxplot algorithm comparison\n",
    "\n",
    "    fig = plt.figure(figsize = ( int(1.2*len(names) ), 8 ) )\n",
    "\n",
    "    fig.suptitle('Algorithm Comparison')\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(n_jobs=-1, max_iter=10000) ) )\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append( ('SVM', SVC(cache_size=1024, max_iter=10000) ) )\n",
    "models.append( ('SVM_R', SVC(kernel='rbf', cache_size=1024, max_iter=10000) ) )\n",
    "\n",
    "models.append( ('BAG_LR', BaggingClassifier(\n",
    "    LogisticRegression(n_jobs=-1, max_iter=10000), \n",
    "    n_estimators=100, max_samples=0.5, max_features=0.5) ) )\n",
    "\n",
    "models.append( ('BAG_LD', BaggingClassifier(\n",
    "    LinearDiscriminantAnalysis(), \n",
    "    n_estimators=100, max_samples=0.5, max_features=0.5) ) )\n",
    "\n",
    "models.append( ('AB_LD', AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
    "        max_depth=9, max_features='auto', min_samples_leaf=3, min_samples_split=3),\n",
    "    learning_rate=1, n_estimators=133) ) )    \n",
    "    \n",
    "models.append( ('ET', ExtraTreesClassifier(n_estimators=100, n_jobs=-1, random_state=0) ) )\n",
    "models.append( ('RF1', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0) ) )\n",
    "\n",
    "models.append( ('RF2', RandomForestClassifier(\n",
    "    class_weight='balanced', criterion='entropy', max_depth=5, max_features='sqrt', \n",
    "    min_samples_leaf=3, min_samples_split=3, n_estimators=178, n_jobs=-1, random_state=0) ) )\n",
    "\n",
    "models.append( ('CF', CalibratedClassifierCV(\n",
    "    base_estimator=RandomForestClassifier(\n",
    "        class_weight='balanced_subsample', criterion='entropy', max_depth=10,\n",
    "        max_features='log2', max_leaf_nodes=9, min_samples_split=5, \n",
    "        n_estimators=178, n_jobs=-1, random_state=0),\n",
    "    cv=5, method='isotonic', n_jobs=-1) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, results = evaluate_all_models(models, X_pca, y)\n",
    "plot_comparison(names, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, results = evaluate_all_models(models, X, y)\n",
    "plot_comparison(names, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv(\"titanic/test.csv\")\n",
    "df = testing.filter([\"PassengerId\"], axis=1)\n",
    "\n",
    "testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = remove_nan(testing, train=False)\n",
    "testing[testing.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = encode_data(testing, train=False)\n",
    "testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = CalibratedClassifierCV(\n",
    "    base_estimator=RandomForestClassifier(\n",
    "        class_weight='balanced_subsample', criterion='entropy', max_depth=10,\n",
    "        max_features='log2', max_leaf_nodes=9, min_samples_split=5, \n",
    "        n_estimators=178, n_jobs=-1, random_state=0),\n",
    "    cv=5, method='isotonic', n_jobs=-1)\n",
    "\n",
    "cf.fit(X_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Survived\"] = rf.predict(testing)\n",
    "\n",
    "# t_pca = pca.transform( testing.values )\n",
    "# df[\"Survived\"] = cf.predict( t_pca )\n",
    "\n",
    "df.to_csv(\"titanic/submission.csv\", index=False)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! kaggle competitions submit -c titanic -f titanic/submission.csv -m \"RandomForestClassifier\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed0a59a19b8c63da79c742e4264cc12e7d2293400754d148e0142cdf47e43bbb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('hsi_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
